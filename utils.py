# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_YJI2QTsQBfVOFiAA1IxXPahOl_Wnvm8
"""

import matplotlib.pyplot as plt
from wordcloud import WordCloud
import streamlit as st
import pandas as pd
import numpy as np

def show_game_description(game):
    st.subheader(f"Tentang {game}")
    if game == "Genshin Impact":
        st.write("Genshin Impact adalah game open-world RPG yang dikembangkan oleh HoYoverse...")
    else:
        st.write("Wuthering Waves adalah game action RPG dengan fitur eksplorasi dunia terbuka...")

def show_sentiment_charts(df, game):
    sentiment_counts = df['sentiment'].value_counts()
    labels = ['Positif', 'Negatif']
    values = [sentiment_counts.get(1, 0), sentiment_counts.get(0, 0)]

    col1, col2 = st.columns(2)
    with col1:
        fig1, ax1 = plt.subplots()
        ax1.pie(values, labels=labels, autopct='%1.1f%%', startangle=90)
        st.pyplot(fig1)

    with col2:
        fig2, ax2 = plt.subplots()
        ax2.bar(labels, values, color=['green', 'red'])
        st.pyplot(fig2)

    st.markdown(f"""
    Dataset berisi total {len(df)} komentar. Terlihat untuk **{game}**,
    terdapat **{values[1]} / {values[1]/len(df)*100:.1f}%** komentar negatif dan
    **{values[0]} / {values[0]/len(df)*100:.1f}%** komentar positif.
    """)

def show_wordclouds(df):
    col1, col2 = st.columns(2)
    for sentiment, label, color, col in zip([1, 0], ["Positif", "Negatif"], ["green", "red"], [col1, col2]):
        text = ' '.join(df[df['sentiment']==sentiment]['komentar'])
        wordcloud = WordCloud(width=300, height=300, background_color='white', colormap=color).generate(text)
        with col:
            st.image(wordcloud.to_array(), caption=f"Word Cloud Sentiment {label}")
            # kata terbanyak
            words = pd.Series(text.split()).value_counts()
            top_word = words.index[0]
            top_count = words.iloc[0]
            st.markdown(f"Pada sentiment {label}, kata paling sering muncul adalah **{top_word}** sebanyak **{top_count} kali**.")

def analyze_user_input(text, model, tokenizer):
    from keras.preprocessing.sequence import pad_sequences
    import numpy as np

    tokens = tokenizer.texts_to_sequences([text])
    padded = pad_sequences(tokens, maxlen=100)

    prediction = model.predict(padded)[0][0]
    sentiment = "Positif" if prediction > 0.5 else "Negatif"

    st.write(f"Kalimat: **{text}**")
    st.write(f"Prediksi Sentimen: **{sentiment}** (score: {prediction:.2f})")